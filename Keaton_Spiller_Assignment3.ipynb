{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 7]\n",
      "[[0 1 0 0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 1 0 0 0]\n",
      " [1 1 1 1 0 0 1 0 1 0]\n",
      " [0 0 0 1 0 0 0 1 0 0]\n",
      " [1 1 0 0 1 0 0 1 1 0]\n",
      " [1 0 1 1 0 0 0 1 0 1]\n",
      " [1 1 0 1 0 1 1 1 1 1]\n",
      " [0 0 1 0 0 1 0 1 0 0]\n",
      " [1 1 1 1 0 1 1 1 1 1]\n",
      " [1 1 0 1 0 1 0 1 1 1]]\n",
      "None\n",
      "{'C': 1, 'N': 0, 'E': 0, 'S': 0, 'W': 1}\n",
      "[6, 7]\n",
      "The chance is: 16\n",
      "random action\n",
      "W\n",
      "Proceed\n",
      "10 Reward, pick up can\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2672/3314289875.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mupdate_Q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_Q\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0meta\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnext_Q\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcurrent_Q\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m         \u001b[0mQ_Matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_Q\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[0mcurrent_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mS_t_next\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "N = 1 # Number of Episodes\n",
    "\n",
    "M = 1 # number of actions to perform in each episode\n",
    "\n",
    "Q_Matrix = {} # (state, actions):Q_Value\n",
    "\n",
    "epsilon = 0.1 # Can start with high Îµ, and decrease it over the run\n",
    "eta = 0.2\n",
    "gamma = 0.9\n",
    "\n",
    "# five â€œsensorsâ€: Current, North, South, East, and West\n",
    "# Values : Empty, Can, and Wall\n",
    "# five possible actions: Move-North, Move-South, Move-East, Move-West, and Pick-Up-Can\n",
    "# reward of 10 for picking up can, -5 crashing into wall \n",
    "# and -1 if he tries to pick up a can in an empty square.\n",
    "\n",
    "# Q(s,a)next = Q(s,a)current + Î· (reward + Î³ max(aÂ´) Q(sÂ´,aÂ´) â€“ Q(s, a)current)\n",
    "\n",
    "\n",
    "def initial_state():\n",
    "            '''\n",
    "            # random 10x10 grid\n",
    "            # Each square has 1/2 probability to contain a can '1'\n",
    "            # Robby is placed in a random square\n",
    "            '''\n",
    "            grid = np.random.binomial(1, p=.5, size=(10,10))\n",
    "            robby = [np.random.choice(np.arange(10)), np.random.choice(np.arange(10))]\n",
    "            return (grid, robby)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# def Q_Learning(s_t, North, East, South, West, Q_Matrix, grid):\n",
    "#     best_score = -100\n",
    "#     alpha = 0.2\n",
    "#     gamma = 0.9\n",
    "#     Q_current = Q_Matrix[(s_t,North)]\n",
    "\n",
    "#             # pickup_can, North, East, South, West = possible_actions(North, s_t)\n",
    "#     max_Q,action = max_Q(s_t, North, grid, Q_Matrix)\n",
    "\n",
    "#             Q_next = Q_current + alpha * (grid[North] + gamma*(children)   )\n",
    "\n",
    "\n",
    "\n",
    "#             if(score > best_score):\n",
    "#                 score == best_score\n",
    "#         if(best_score == -100):\n",
    "\n",
    "#     if(action == False):\n",
    "#         return (-1)\n",
    "\n",
    "# # def greedy_action_selection(robby, s_t, grid, Q_Matrix):\n",
    "# def max_action():\n",
    "\n",
    "def max_Q(sensors, Q_Matrix, robby):\n",
    "    print(robby)\n",
    "    \n",
    "    best_Q = 0\n",
    "    for i,a in enumerate(sensors):\n",
    "        key = tuple(robby) + tuple(str(a))\n",
    "        if(key in Q_Matrix):\n",
    "            Q = Q_Matrix[key]\n",
    "            if(Q > best_Q):\n",
    "                best_Q = Q\n",
    "                action = a\n",
    "    if(best_Q == 0):\n",
    "        action = 'N'\n",
    "\n",
    "    return (action)\n",
    "\n",
    "def epsilon_greedy(epsilon, sensors, grid, robby, Q_Matrix):\n",
    "    a =['C', 'N', 'E', 'S', 'W']\n",
    "    # With probability (1 âˆ’ Îµ)  choose action that maximizes current Q(s,a)\n",
    "    # With probability Îµ choose random action\n",
    "    prob_random = epsilon * 1000\n",
    "    chance = np.random.randint(0, 1000) # Inclusive to exclusive\n",
    "    print(f\"The chance is: {chance}\")\n",
    "    if(chance >=prob_random):\n",
    "        print(\"max Action\")\n",
    "        action = max_Q(sensors, Q_Matrix, robby)\n",
    "    if(chance < prob_random):\n",
    "        print(\"random action\")\n",
    "        chance = np.random.randint(0, 5) \n",
    "        action = str(a[chance])\n",
    "\n",
    "    return(action)\n",
    "\n",
    "def possible_actions(grid, robby):\n",
    "    # 0 empty cell, 1 is can, 2 is wall\n",
    "    sensors = {}\n",
    "    x = robby[0]\n",
    "    y = robby[1]\n",
    "    score = grid[robby[0], robby[1]] # robby's current state\n",
    "    if(score == 1):\n",
    "        sensors['C'] = 1\n",
    "    if(score!= 1):\n",
    "        sensors['C'] = 0\n",
    "\n",
    "    # Move-North\n",
    "    North = (x,y+1)\n",
    "    if(North[1] == 10):\n",
    "        sensors['N'] = 2\n",
    "    if(North[1] != 10):\n",
    "        if(grid[North[0]][North[1]] == 1):\n",
    "            sensors['N'] = 1\n",
    "        if(grid[North[0]][North[1]] == 0):\n",
    "            sensors['N'] = 0\n",
    "\n",
    "    # Move-East\n",
    "    East = (x+1,y)\n",
    "    if(East[0] == 10):\n",
    "        sensors['E'] = 2\n",
    "    if(East[0] != 10):\n",
    "        if(grid[East[0]][East[1]] == 1):\n",
    "            sensors['E'] = 1\n",
    "        if(grid[East[0]][East[1]] == 0):\n",
    "            sensors['E'] = 0\n",
    "\n",
    "    # Move-South\n",
    "    South = (x,y-1)\n",
    "    if(South[1] == -1):\n",
    "        sensors['S'] = 2\n",
    "    if(South[1] != -1):\n",
    "        if(grid[South[0]][South[1]] == 1):\n",
    "            sensors['S'] = 1\n",
    "        if(grid[South[0]][South[1]] == 0):\n",
    "            sensors['S'] = 0\n",
    "        \n",
    "    # Move-West\n",
    "    West = (x-1,y)\n",
    "    if(West[0] == -1):\n",
    "        sensors['W'] = 2\n",
    "    if(West[0] != -1):\n",
    "        if(grid[West[0]][West[1]] == 1):\n",
    "            sensors['W'] = 1\n",
    "        if(grid[West[0]][West[1]] == 0):\n",
    "            sensors['W'] = 0\n",
    "    return(sensors)\n",
    "\n",
    "\n",
    "def next_state(action, grid, current):\n",
    "    x = current[0]\n",
    "    y = current[1]\n",
    "    if(action == 'C'):\n",
    "        return(current)\n",
    "    if(action == 'N'):\n",
    "        return grid[x][y+1]\n",
    "    if(action == 'E'):\n",
    "        return grid[x+1][y]\n",
    "    if(action == 'S'):\n",
    "        return grid[x][y-1]\n",
    "    if(action == 'W'):\n",
    "        return grid[x-1][y]\n",
    "\n",
    "def next_state_and_reward(a_t, sensors, grid, current):\n",
    "    # {'C': 1, 'N': 0, 'E': 0, 'S': 1, 'W': 0}\n",
    "    if(sensors[a_t] == 0):\n",
    "        print(\"Proceed\")\n",
    "        print('0 Reward')\n",
    "        S_t_next = next_state(action, grid, current)\n",
    "        reward = 0\n",
    "    if(sensors[a_t] == 1):\n",
    "        print(\"Proceed\")\n",
    "        print('10 Reward, pick up can')\n",
    "        S_t_next = next_state(action, grid, current)\n",
    "        grid[current]= 0\n",
    "        reward = 10\n",
    "\n",
    "    if(sensors[a_t] == 2):\n",
    "        S_t_next = current\n",
    "        print(\"Wall\")\n",
    "        reward = -5\n",
    "    return (S_t_next, reward, grid)\n",
    "\n",
    "for episode in range(N):\n",
    "    grid, robby = initial_state()\n",
    "    current_state = robby\n",
    "    a_t = 'C' # initial state\n",
    "    for action in range(M):\n",
    "        print(current_state)\n",
    "        print(print(grid[::-1,:])) # display 0,0 at bottom left\n",
    "        sensors = possible_actions(grid, current_state)\n",
    "        print(sensors)\n",
    "        \n",
    "        # current Q\n",
    "        key = tuple(current_state) + tuple(a_t)\n",
    "        if(key in Q_Matrix):\n",
    "            current_Q = Q_Matrix[key]\n",
    "        if(key not in Q_Matrix):\n",
    "            current_Q = 0\n",
    "            print(current_state)\n",
    "            # key = tuple(current_state) + tuple(a_t) \n",
    "            Q_Matrix[key] = 0\n",
    "\n",
    "        a_t = epsilon_greedy(epsilon, sensors, grid, current_state, Q_Matrix)\n",
    "\n",
    "        print(a_t)\n",
    "        S_t_next, reward, grid = next_state_and_reward(a_t, sensors, grid, current_state)\n",
    "\n",
    "        key2 = tuple(S_t_next) + tuple(a_t)\n",
    "        update = tuple(current_state) + tuple(a_t)\n",
    "        if(key in Q_Matrix): \n",
    "            next_Q = Q_Matrix[update]\n",
    "        if(key not in Q_Matrix):\n",
    "            next_Q = 0\n",
    "        \n",
    "        update_Q = current_Q + (eta * (reward + (gamma * next_Q) - current_Q) )\n",
    "\n",
    "        Q_Matrix[update] = update_Q\n",
    "\n",
    "        current_state = S_t_next\n",
    "            \n",
    "    \n",
    "# epsilon = 0.1 # Can start with high Îµ, and decrease it over the run\n",
    "# eta = 0.2\n",
    "# gamma = 0.9\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ex. test N = 5,000 ; M = 200 ; ðœ‚= 0.2; ð›¾= 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(3, 4, 'N'): 4}\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "a = [3, 4]\n",
    "\n",
    "b = 'N'\n",
    "key = tuple(a) + tuple(b)\n",
    "\n",
    "d[key] = 4\n",
    "\n",
    "print(d)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "829c3b8be07045a118e2051d32961b742b1ec2887b2f995a302577c84815eb30"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
